{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "loading_model_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girijeshcse/computervisionTFKeras/blob/main/loading_model_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# Load a trained Keras/TensorFlow model from disk\n",
        "### by [PyImageSearch.com](http://www.pyimagesearch.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhAzQB3aNMa"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0LG1EuaRlB"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/loading-model-keras/loading-model-keras.zip\n",
        "!unzip -qq loading-model-keras.zip\n",
        "%cd loading-model-keras\n",
        "!wget https://pis-datasets.s3.us-east-2.amazonaws.com/animals.zip\n",
        "!unzip -qq animals.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u4dX25-Z-pO"
      },
      "source": [
        "# import the necessary packages\n",
        "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
        "from pyimagesearch.preprocessing import SimplePreprocessor\n",
        "from pyimagesearch.datasets import SimpleDatasetLoader\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY1ceK63OuFY"
      },
      "source": [
        "### Function to display images in Jupyter Notebooks and Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkPDb7emOuwQ"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.grid(False)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBtHDi7wGCwT"
      },
      "source": [
        "### Loading a Pre-trained Model from Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nY3gflwFgXl"
      },
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
        "# \thelp=\"path to input dataset\")\n",
        "# ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "# \thelp=\"path to pre-trained model\")\n",
        "# args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "\t\"dataset\": \"animals\",\n",
        "    \"model\": \"shallownet_weights.hdf5\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J07PhTcEGfnS"
      },
      "source": [
        "# initialize the class labels\n",
        "classLabels = [\"cat\", \"dog\", \"panda\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZMsQx9qGjZT"
      },
      "source": [
        "# grab the list of images in the dataset then randomly sample\n",
        "# indexes into the image paths list\n",
        "print(\"[INFO] sampling images...\")\n",
        "imagePaths = np.array(list(paths.list_images(args[\"dataset\"])))\n",
        "idxs = np.random.randint(0, len(imagePaths), size=(10,))\n",
        "imagePaths = imagePaths[idxs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlQgOWpkG0gq"
      },
      "source": [
        "# initialize the image preprocessors\n",
        "sp = SimplePreprocessor(32, 32)\n",
        "iap = ImageToArrayPreprocessor()\n",
        "\n",
        "# load the dataset from disk then scale the raw pixel intensities\n",
        "# to the range [0, 1]\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
        "(data, labels) = sdl.load(imagePaths)\n",
        "data = data.astype(\"float\") / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N6aLd0TG05-"
      },
      "source": [
        "# load the pre-trained network\n",
        "print(\"[INFO] loading pre-trained network...\")\n",
        "model = load_model(args[\"model\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO6DKfXNG5MZ"
      },
      "source": [
        "# make predictions on the images\n",
        "print(\"[INFO] predicting...\")\n",
        "preds = model.predict(data, batch_size=32).argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWiYk6GDG-Dh"
      },
      "source": [
        "# loop over the sample images\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# load the example image, draw the prediction, and display it\n",
        "\t# to our screen\n",
        "\timage = cv2.imread(imagePath)\n",
        "\tcv2.putText(image, \"Label: {}\".format(classLabels[preds[i]]),\n",
        "\t\t(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\tplt_imshow(\"Image\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIK0y_52aETm"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Load a trained Keras/TensorFlow model from disk*](https://www.pyimagesearch.com/2021/05/22/load-a-trained-keras-tensorflow-model-from-disk/) published on 2021-05-22."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwMZ9cZaaLG4"
      },
      "source": [
        "# Code License Agreement\n",
        "```\n",
        "Copyright (c) 2021 PyImageSearch.com\n",
        "\n",
        "SIMPLE VERSION\n",
        "Feel free to use this code for your own projects, whether they are\n",
        "purely educational, for fun, or for profit. THE EXCEPTION BEING if\n",
        "you are developing a course, book, or other educational product.\n",
        "Under *NO CIRCUMSTANCE* may you use this code for your own paid\n",
        "educational or self-promotional ventures without written consent\n",
        "from Adrian Rosebrock and PyImageSearch.com.\n",
        "\n",
        "LONGER, FORMAL VERSION\n",
        "Permission is hereby granted, free of charge, to any person obtaining\n",
        "a copy of this software and associated documentation files\n",
        "(the \"Software\"), to deal in the Software without restriction,\n",
        "including without limitation the rights to use, copy, modify, merge,\n",
        "publish, distribute, sublicense, and/or sell copies of the Software,\n",
        "and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be\n",
        "included in all copies or substantial portions of the Software.\n",
        "Notwithstanding the foregoing, you may not use, copy, modify, merge,\n",
        "publish, distribute, sublicense, create a derivative work, and/or\n",
        "sell copies of the Software in any work that is designed, intended,\n",
        "or marketed for pedagogical or instructional purposes related to\n",
        "programming, coding, application development, or information\n",
        "technology. Permission for such use, copying, modification, and\n",
        "merger, publication, distribution, sub-licensing, creation of\n",
        "derivative works, or sale is expressly withheld.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
        "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n",
        "OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
        "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n",
        "BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n",
        "ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "```"
      ]
    }
  ]
}