{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier_to_detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girijeshcse/computervisionTFKeras/blob/main/object_detection/01%20classifier_to_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAckSQgGaGHY"
      },
      "source": [
        "### Install the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9FkaOfWwawu"
      },
      "source": [
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhAzQB3aNMa"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0LG1EuaRlB"
      },
      "source": [
        "!wget https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/classifier-to-detector/classifier-to-detector.zip\n",
        "!unzip -qq classifier-to-detector.zip\n",
        "%cd classifier-to-detector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from imutils.object_detection import non_max_suppression\n",
        "from pyimagesearch.detection_helpers import sliding_window\n",
        "from pyimagesearch.detection_helpers import image_pyramid\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBrLwCtN5kqy"
      },
      "source": [
        "### Function to display images in Jupyter Notebooks and Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRw969Dp5Kdm"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "\t# convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QspFMqAX1qA"
      },
      "source": [
        "### Implementing our image pyramid and sliding window utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cg1n8vDX4Nv"
      },
      "source": [
        "def sliding_window(image, step, ws):\n",
        "\t# slide a window across the image\n",
        "\tfor y in range(0, image.shape[0] - ws[1], step):\n",
        "\t\tfor x in range(0, image.shape[1] - ws[0], step):\n",
        "\t\t\t# yield the current window\n",
        "\t\t\tyield (x, y, image[y:y + ws[1], x:x + ws[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW6oxxayX6j6"
      },
      "source": [
        "def image_pyramid(image, scale=1.5, minSize=(224, 224)):\n",
        "\t# yield the original image\n",
        "\tyield image\n",
        "\n",
        "\t# keep looping over the image pyramid\n",
        "\twhile True:\n",
        "\t\t# compute the dimensions of the next image in the pyramid\n",
        "\t\tw = int(image.shape[1] / scale)\n",
        "\t\timage = imutils.resize(image, width=w)\n",
        "\n",
        "\t\t# if the resized image does not meet the supplied minimum\n",
        "\t\t# size, then stop constructing the pyramid\n",
        "\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\t# yield the next image in the pyramid\n",
        "\t\tyield image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Using Keras and TensorFlow to turn a pre-trained image classifier into an object detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc"
      },
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "#\thelp=\"path to the input image\")\n",
        "#ap.add_argument(\"-s\", \"--size\", type=str, default=\"(200, 150)\",\n",
        "#\thelp=\"ROI size (in pixels)\")\n",
        "#ap.add_argument(\"-c\", \"--min-conf\", type=float, default=0.9,\n",
        "#\thelp=\"minimum probability to filter weak detections\")\n",
        "#ap.add_argument(\"-v\", \"--visualize\", type=int, default=-1,\n",
        "#\thelp=\"whether or not to show extra visualizations for debugging\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "\t\"image\": \"images/stingray.jpg\",\n",
        "\t\"size\": \"(300, 150)\",\n",
        "\t\"min_conf\": 0.9,\n",
        "\t\"visualize\": -1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3AwvDvOY5cF"
      },
      "source": [
        "# initialize variables used for the object detection procedure\n",
        "WIDTH = 600\n",
        "PYR_SCALE = 1.5\n",
        "WIN_STEP = 16\n",
        "ROI_SIZE = eval(args[\"size\"])\n",
        "INPUT_SIZE = (224, 224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBywJiL9Y6D1"
      },
      "source": [
        "# load our network weights from disk\n",
        "print(\"[INFO] loading network...\")\n",
        "model = ResNet50(weights=\"imagenet\", include_top=True)\n",
        "\n",
        "# load the input image from disk, resize it such that it has the\n",
        "# has the supplied width, and then grab its dimensions\n",
        "orig = cv2.imread(args[\"image\"])\n",
        "orig = imutils.resize(orig, width=WIDTH)\n",
        "(H, W) = orig.shape[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGPo-IK1Y9Jr"
      },
      "source": [
        "# initialize the image pyramid\n",
        "pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n",
        "\n",
        "# initialize two lists, one to hold the ROIs generated from the image\n",
        "# pyramid and sliding window, and another list used to store the\n",
        "# (x, y)-coordinates of where the ROI was in the original image\n",
        "rois = []\n",
        "locs = []\n",
        "\n",
        "# time how long it takes to loop over the image pyramid layers and\n",
        "# sliding window locations\n",
        "start = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2is0GigY_p3"
      },
      "source": [
        "# loop over the image pyramid\n",
        "for image in pyramid:\n",
        "\t# determine the scale factor between the *original* image\n",
        "\t# dimensions and the *current* layer of the pyramid\n",
        "\tscale = W / float(image.shape[1])\n",
        "\n",
        "\t# for each layer of the image pyramid, loop over the sliding\n",
        "\t# window locations\n",
        "\tfor (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
        "\t\t# scale the (x, y)-coordinates of the ROI with respect to the\n",
        "\t\t# *original* image dimensions\n",
        "\t\tx = int(x * scale)\n",
        "\t\ty = int(y * scale)\n",
        "\t\tw = int(ROI_SIZE[0] * scale)\n",
        "\t\th = int(ROI_SIZE[1] * scale)\n",
        "\n",
        "\t\t# take the ROI and preprocess it so we can later classify\n",
        "\t\t# the region using Keras/TensorFlow\n",
        "\t\troi = cv2.resize(roiOrig, INPUT_SIZE)\n",
        "\t\troi = img_to_array(roi)\n",
        "\t\troi = preprocess_input(roi)\n",
        "\n",
        "\t\t# update our list of ROIs and associated coordinates\n",
        "\t\trois.append(roi)\n",
        "\t\tlocs.append((x, y, x + w, y + h))\n",
        "\n",
        "        # check to see if we are visualizing each of the sliding\n",
        "\t\t# windows in the image pyramid\n",
        "\t\tif args[\"visualize\"] > 0:\n",
        "\t\t\t# clone the original image and then draw a bounding box\n",
        "\t\t\t# surrounding the current region\n",
        "\t\t\tclone = orig.copy()\n",
        "\t\t\tcv2.rectangle(clone, (x, y), (x + w, y + h),\n",
        "\t\t\t\t(0, 255, 0), 2)\n",
        "\n",
        "\t\t\t# show the visualization and current ROI\n",
        "\t\t\tplt_imshow(\"Visualization\", clone)\n",
        "\t\t\tplt_imshow(\"ROI\", roiOrig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om9MMjEZZNHF"
      },
      "source": [
        "# show how long it took to loop over the image pyramid layers and\n",
        "# sliding window locations\n",
        "end = time.time()\n",
        "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n",
        "\tend - start))\n",
        "\n",
        "# convert the ROIs to a NumPy array\n",
        "rois = np.array(rois, dtype=\"float32\")\n",
        "\n",
        "# classify each of the proposal ROIs using ResNet and then show how\n",
        "# long the classifications took\n",
        "print(\"[INFO] classifying ROIs...\")\n",
        "start = time.time()\n",
        "preds = model.predict(rois)\n",
        "end = time.time()\n",
        "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
        "\tend - start))\n",
        "\n",
        "# decode the predictions and initialize a dictionary which maps class\n",
        "# labels (keys) to any ROIs associated with that label (values)\n",
        "preds = imagenet_utils.decode_predictions(preds, top=1)\n",
        "labels = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K45v90a9ZRhi"
      },
      "source": [
        "# loop over the predictions\n",
        "for (i, p) in enumerate(preds):\n",
        "\t# grab the prediction information for the current ROI\n",
        "\t(imagenetID, label, prob) = p[0]\n",
        "\n",
        "\t# filter out weak detections by ensuring the predicted probability\n",
        "\t# is greater than the minimum probability\n",
        "\tif prob >= args[\"min_conf\"]:\n",
        "\t\t# grab the bounding box associated with the prediction and\n",
        "\t\t# convert the coordinates\n",
        "\t\tbox = locs[i]\n",
        "\n",
        "\t\t# grab the list of predictions for the label and add the\n",
        "\t\t# bounding box and probability to the list\n",
        "\t\tL = labels.get(label, [])\n",
        "\t\tL.append((box, prob))\n",
        "\t\tlabels[label] = L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vio_AfY3ZUmo"
      },
      "source": [
        "# loop over the labels for each of detected objects in the image\n",
        "for label in labels.keys():\n",
        "\t# clone the original image so that we can draw on it\n",
        "\tprint(\"[INFO] showing results for '{}'\".format(label))\n",
        "\tclone = orig.copy()\n",
        "\n",
        "\t# loop over all bounding boxes for the current label\n",
        "\tfor (box, prob) in labels[label]:\n",
        "\t\t# draw the bounding box on the image\n",
        "\t\t(startX, startY, endX, endY) = box\n",
        "\t\tcv2.rectangle(clone, (startX, startY), (endX, endY),\n",
        "\t\t\t(0, 255, 0), 2)\n",
        "\n",
        "\t# show the results *before* applying non-maxima suppression, then\n",
        "\t# clone the image again so we can display the results *after*\n",
        "\t# applying non-maxima suppression\n",
        "\tplt_imshow(\"Before\", clone)\n",
        "\tclone = orig.copy()\n",
        "\n",
        "    # extract the bounding boxes and associated prediction\n",
        "\t# probabilities, then apply non-maxima suppression\n",
        "\tboxes = np.array([p[0] for p in labels[label]])\n",
        "\tproba = np.array([p[1] for p in labels[label]])\n",
        "\tboxes = non_max_suppression(boxes, proba)\n",
        "\n",
        "\t# loop over all bounding boxes that were kept after applying\n",
        "\t# non-maxima suppression\n",
        "\tfor (startX, startY, endX, endY) in boxes:\n",
        "\t\t# draw the bounding box and label on the image\n",
        "\t\tcv2.rectangle(clone, (startX, startY), (endX, endY),\n",
        "\t\t\t(0, 255, 0), 2)\n",
        "\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "\t\tcv2.putText(clone, label, (startX, y),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "\n",
        "\t# show the output after apply non-maxima suppression\n",
        "\tplt_imshow(\"After\", clone)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}